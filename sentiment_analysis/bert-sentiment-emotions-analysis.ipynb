{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"markdown","source":"The dataset was taken from here: https://huggingface.co/datasets/emotion. The model used to classify emotions in text messages is BERT, that is very popular for solving NLP tasks","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Preparation","metadata":{}},{"cell_type":"code","source":"!pip install transformers lets_plot -q","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:09.796116Z","iopub.execute_input":"2023-01-07T07:00:09.796597Z","iopub.status.idle":"2023-01-07T07:00:21.884865Z","shell.execute_reply.started":"2023-01-07T07:00:09.796487Z","shell.execute_reply":"2023-01-07T07:00:21.883723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lets_plot import *\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, DistilBertTokenizer, BertForSequenceClassification\nfrom sklearn.metrics import accuracy_score, f1_score\n\nimport matplotlib.pyplot as plt \nimport pytorch_lightning as pl\nimport pandas as pd\nimport numpy as np\nimport os\nimport pickle\nimport time\nimport torch.nn as nn\nimport torch\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:21.888731Z","iopub.execute_input":"2023-01-07T07:00:21.889045Z","iopub.status.idle":"2023-01-07T07:00:26.958001Z","shell.execute_reply.started":"2023-01-07T07:00:21.889011Z","shell.execute_reply":"2023-01-07T07:00:26.957000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():    \n    device = torch.device(\"cuda\")\n    print(f'Using GPU : {torch.cuda.get_device_name(0)}')\nelse:\n    device = torch.device(\"cpu\")\n    print(f'Using CPU')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:26.959375Z","iopub.execute_input":"2023-01-07T07:00:26.961075Z","iopub.status.idle":"2023-01-07T07:00:27.032515Z","shell.execute_reply.started":"2023-01-07T07:00:26.961032Z","shell.execute_reply":"2023-01-07T07:00:27.031581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.035997Z","iopub.execute_input":"2023-01-07T07:00:27.036337Z","iopub.status.idle":"2023-01-07T07:00:27.048274Z","shell.execute_reply.started":"2023-01-07T07:00:27.036310Z","shell.execute_reply":"2023-01-07T07:00:27.047284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LetsPlot.setup_html()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.051362Z","iopub.execute_input":"2023-01-07T07:00:27.051661Z","iopub.status.idle":"2023-01-07T07:00:27.061393Z","shell.execute_reply.started":"2023-01-07T07:00:27.051619Z","shell.execute_reply":"2023-01-07T07:00:27.060470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading & Preprocessing","metadata":{}},{"cell_type":"code","source":"path_to_data_pkl = '/kaggle/input/emotionsdata/merged_training.pkl'","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.064257Z","iopub.execute_input":"2023-01-07T07:00:27.064569Z","iopub.status.idle":"2023-01-07T07:00:27.069556Z","shell.execute_reply.started":"2023-01-07T07:00:27.064542Z","shell.execute_reply":"2023-01-07T07:00:27.068306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(path_to_data_pkl, 'rb') as file:\n    data = pickle.load(file)\n    print(f'Got data of shape : {data.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.071156Z","iopub.execute_input":"2023-01-07T07:00:27.072005Z","iopub.status.idle":"2023-01-07T07:00:27.783806Z","shell.execute_reply.started":"2023-01-07T07:00:27.071969Z","shell.execute_reply":"2023-01-07T07:00:27.782747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.rename(columns={'emotions' : 'label'}, inplace=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.785412Z","iopub.execute_input":"2023-01-07T07:00:27.786046Z","iopub.status.idle":"2023-01-07T07:00:27.808260Z","shell.execute_reply.started":"2023-01-07T07:00:27.786007Z","shell.execute_reply":"2023-01-07T07:00:27.807264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.809811Z","iopub.execute_input":"2023-01-07T07:00:27.810092Z","iopub.status.idle":"2023-01-07T07:00:27.859289Z","shell.execute_reply.started":"2023-01-07T07:00:27.810066Z","shell.execute_reply":"2023-01-07T07:00:27.858072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequency = data.label.value_counts()\nfrequency","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.863780Z","iopub.execute_input":"2023-01-07T07:00:27.864600Z","iopub.status.idle":"2023-01-07T07:00:27.887328Z","shell.execute_reply.started":"2023-01-07T07:00:27.864565Z","shell.execute_reply":"2023-01-07T07:00:27.886210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequency = pd.DataFrame({\n    'Labels' : frequency.index,\n    'Total' : frequency.values\n})","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.889155Z","iopub.execute_input":"2023-01-07T07:00:27.889503Z","iopub.status.idle":"2023-01-07T07:00:27.897550Z","shell.execute_reply.started":"2023-01-07T07:00:27.889468Z","shell.execute_reply":"2023-01-07T07:00:27.896583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ggplot(frequency, aes(x=frequency.Labels, weight=frequency.Total, fill=frequency.Labels)) + \\\n    geom_bar() + labs(x='Label', y='Times Occured')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:27.898582Z","iopub.execute_input":"2023-01-07T07:00:27.900250Z","iopub.status.idle":"2023-01-07T07:00:28.281973Z","shell.execute_reply.started":"2023-01-07T07:00:27.900214Z","shell.execute_reply":"2023-01-07T07:00:28.281010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, we got a lot of text messages with labeled emotions - `joy`, `sadness`, `anger`, `fear`, `love`, `surprise`.","metadata":{}},{"cell_type":"code","source":"label_to_id = {'0' : 'joy', '1' : 'sadness', '2' : 'anger', '3' : 'fear', '4' : 'love', '5' : 'surprise'}\nid_to_label = {v : k for k, v in label_to_id.items()}","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.284418Z","iopub.execute_input":"2023-01-07T07:00:28.285004Z","iopub.status.idle":"2023-01-07T07:00:28.291068Z","shell.execute_reply.started":"2023-01-07T07:00:28.284974Z","shell.execute_reply":"2023-01-07T07:00:28.290190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll map each label to its id","metadata":{}},{"cell_type":"code","source":"data.label = data.label.map(id_to_label)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.292297Z","iopub.execute_input":"2023-01-07T07:00:28.293106Z","iopub.status.idle":"2023-01-07T07:00:28.339077Z","shell.execute_reply.started":"2023-01-07T07:00:28.293067Z","shell.execute_reply":"2023-01-07T07:00:28.338190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.342494Z","iopub.execute_input":"2023-01-07T07:00:28.342780Z","iopub.status.idle":"2023-01-07T07:00:28.355584Z","shell.execute_reply.started":"2023-01-07T07:00:28.342755Z","shell.execute_reply":"2023-01-07T07:00:28.354419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we create own custom Dataloader based on our splitted into `train`, `val`, `test` dataset","metadata":{}},{"cell_type":"code","source":"TEST_SIZE = 0.2\nVAL_SIZE = 0.1\nTRAIN_SIZE = 1 - (VAL_SIZE + TEST_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.357059Z","iopub.execute_input":"2023-01-07T07:00:28.358830Z","iopub.status.idle":"2023-01-07T07:00:28.363341Z","shell.execute_reply.started":"2023-01-07T07:00:28.358802Z","shell.execute_reply":"2023-01-07T07:00:28.362199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data.text, data.label, test_size=TEST_SIZE, random_state=seed)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VAL_SIZE, random_state=seed) ","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.364413Z","iopub.execute_input":"2023-01-07T07:00:28.364803Z","iopub.status.idle":"2023-01-07T07:00:28.515810Z","shell.execute_reply.started":"2023-01-07T07:00:28.364769Z","shell.execute_reply":"2023-01-07T07:00:28.514841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentimentTextDataset(Dataset):\n    def __init__(self, text, labels):\n        self.text = text\n        self.labels = labels\n        \n    def __len__(self):\n        assert len(self.text) == len(self.labels)\n        return len(self.labels)\n    \n    def __getitem__(self, index):\n        text_msg = self.text.iloc[index]\n        label = self.labels.iloc[index]\n        return text_msg, label","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.517446Z","iopub.execute_input":"2023-01-07T07:00:28.517820Z","iopub.status.idle":"2023-01-07T07:00:28.526488Z","shell.execute_reply.started":"2023-01-07T07:00:28.517783Z","shell.execute_reply":"2023-01-07T07:00:28.525519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = SentimentTextDataset(X_train, y_train)\nval_dataset = SentimentTextDataset(X_val, y_val)\ntest_dataset = SentimentTextDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.527799Z","iopub.execute_input":"2023-01-07T07:00:28.528065Z","iopub.status.idle":"2023-01-07T07:00:28.536748Z","shell.execute_reply.started":"2023-01-07T07:00:28.528040Z","shell.execute_reply":"2023-01-07T07:00:28.535855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train set size: {len(train_dataset)} - {int(TRAIN_SIZE * 100)}% of all data')\nprint(f'Validation set size : {len(val_dataset)} - {int(VAL_SIZE * 100)}% of all data')\nprint(f'Test set size : {len(test_dataset)} - {int(TEST_SIZE * 100)}% of all data')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.538011Z","iopub.execute_input":"2023-01-07T07:00:28.538293Z","iopub.status.idle":"2023-01-07T07:00:28.547053Z","shell.execute_reply.started":"2023-01-07T07:00:28.538268Z","shell.execute_reply":"2023-01-07T07:00:28.546059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We do not really much epochs of training on our dataset, since we only fine-tune our already pretrained on large corpus model. By the way, training one epoch takes 2-3 hours of GPU computation and with more epochs it will actually overfit quite fast.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 48\nLR = 4e-5\nEPOCH = 2","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.548369Z","iopub.execute_input":"2023-01-07T07:00:28.548671Z","iopub.status.idle":"2023-01-07T07:00:28.556712Z","shell.execute_reply.started":"2023-01-07T07:00:28.548646Z","shell.execute_reply":"2023-01-07T07:00:28.555594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = DataLoader(train_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True,\n                              num_workers=8)\n\nval_data_loader = DataLoader(val_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=False,\n                              num_workers=8)\n\ntest_data_loader = DataLoader(test_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=False,\n                              num_workers=8)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.558004Z","iopub.execute_input":"2023-01-07T07:00:28.558659Z","iopub.status.idle":"2023-01-07T07:00:28.566806Z","shell.execute_reply.started":"2023-01-07T07:00:28.558624Z","shell.execute_reply":"2023-01-07T07:00:28.566193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BERT\n\nWe are going to use BERT transformer model. We need to tokenize text before passing it to our model. ","metadata":{}},{"cell_type":"markdown","source":"### Set-Up","metadata":{}},{"cell_type":"code","source":"model_name_bert = 'bert-base-uncased'","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.567834Z","iopub.execute_input":"2023-01-07T07:00:28.568195Z","iopub.status.idle":"2023-01-07T07:00:28.577904Z","shell.execute_reply.started":"2023-01-07T07:00:28.568159Z","shell.execute_reply":"2023-01-07T07:00:28.576948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(model_name_bert)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:28.579228Z","iopub.execute_input":"2023-01-07T07:00:28.580038Z","iopub.status.idle":"2023-01-07T07:00:31.597466Z","shell.execute_reply.started":"2023-01-07T07:00:28.580004Z","shell.execute_reply":"2023-01-07T07:00:31.596563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = np.zeros(len(data))\nfor i in range(len(data)):\n    input_ids = tokenizer.encode(data.text.iloc[i], add_special_tokens=True)\n    max_len[i] = len(input_ids)\nprint('Max length: ', max_len.max())\n\ndel input_ids\ndel max_len","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:00:31.598876Z","iopub.execute_input":"2023-01-07T07:00:31.599327Z","iopub.status.idle":"2023-01-07T07:00:31.603945Z","shell.execute_reply.started":"2023-01-07T07:00:31.599283Z","shell.execute_reply":"2023-01-07T07:00:31.602867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also need to provide our model with `pytorch lightning module` functionality","metadata":{}},{"cell_type":"code","source":"class BertModel(pl.LightningModule):\n    def __init__(self, tokenizer, max_len, lr=LR):\n        super().__init__()\n        self.model = BertForSequenceClassification.from_pretrained(model_name_bert, num_labels=data.label.nunique())        \n        self.loss = nn.functional.cross_entropy\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.softmax = nn.Softmax()\n        self.lr = lr\n        self.losses_train = []\n        self.losses_val = []\n        \n    def forward(self, x):\n        encoding = self.tokenizer(\n          x,\n          add_special_tokens=True,\n          max_length=self.max_len,\n          return_token_type_ids=False,\n          pad_to_max_length=True,\n          return_attention_mask=True,\n          return_tensors='pt',\n          truncation=True\n        ).to(device)\n        \n        return self.model(**encoding)\n    \n    def training_step(self, batch, batch_idx):\n        text_msg, y_true = batch\n        y_true = torch.tensor(np.array(list(y_true)).astype(np.uint8)).to(device)\n        logits = self.forward(text_msg).logits\n        loss = self.loss(logits, y_true)\n        softmax = self.softmax(logits)\n        y_pred = torch.argmax(softmax, dim=1).to(device)\n        \n        accuracy = torch.tensor(accuracy_score(y_true.cpu().numpy(), y_pred.cpu().numpy()))\n        f1 = torch.tensor(f1_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average=\"macro\"))\n        self.losses_train.append(loss)\n        return {'loss' : loss, 'accuracy' : accuracy, 'f1' : f1}\n    \n    def validation_step(self, batch, batch_idx):\n        text_msg, y_true = batch\n        y_true = torch.tensor(np.array(list(y_true)).astype(np.uint8)).to(device)\n        logits = self.forward(text_msg).logits\n        loss = self.loss(logits, y_true)\n        softmax = self.softmax(logits)\n        y_pred = torch.argmax(softmax, dim=1).to(device)\n        \n        accuracy = torch.tensor(accuracy_score(y_true.cpu().numpy(), y_pred.cpu().numpy()))\n        f1 = torch.tensor(f1_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average=\"macro\"))\n        self.losses_val.append(loss)\n        return {'val_loss' : loss, 'val_accuracy' : accuracy, 'val_f1' : f1}\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        avg_acc = torch.stack([x['accuracy'] for x in outputs]).mean()\n        avg_f1 = torch.stack([x['f1'] for x in outputs]).mean()\n        \n        print(f\"Train_loss: {avg_loss:.2f}\")\n        print(f\"Train_accuracy: {avg_acc:.2f}\")\n        print(f\"Train_f1: {avg_f1:.2f}\")\n        \n        self.log('loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n        \n    def predict_step(self, batch, batch_idx):\n        if isinstance(batch, list):\n            if len(batch) > 1:\n                text_msg, _ = batch\n        else:\n            text_msg = batch\n        output = self.forward(text_msg).logits.to(device)\n        probs =  self.softmax(output).to(device)\n        return torch.argmax(probs, dim=1)\n        \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        avg_acc = torch.stack([x['val_accuracy'] for x in outputs]).mean()\n        avg_f1 = torch.stack([x['val_f1'] for x in outputs]).mean()\n        \n        print(f\"Val_loss: {avg_loss:.2f}\", end= \" \")\n        print(f\"Val_accuracy: {avg_acc:.2f}\", end= \" \")\n        print(f\"Val_f1 {avg_loss:.2f}\", end= \" \")\n        \n        self.log('val_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n    \n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-6)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:04:59.111075Z","iopub.execute_input":"2023-01-07T07:04:59.111461Z","iopub.status.idle":"2023-01-07T07:04:59.135245Z","shell.execute_reply.started":"2023-01-07T07:04:59.111430Z","shell.execute_reply":"2023-01-07T07:04:59.134386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"bert_model = BertModel(tokenizer, max_len=256)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:04:59.756632Z","iopub.execute_input":"2023-01-07T07:04:59.757029Z","iopub.status.idle":"2023-01-07T07:05:01.940781Z","shell.execute_reply.started":"2023-01-07T07:04:59.756967Z","shell.execute_reply":"2023-01-07T07:05:01.939890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_check_point = ModelCheckpoint(dirpath='runs/bert_emotion',\n                                    filename='{epoch}-{val_loss:.3f}',\n                                    monitor='val_loss', \n                                    mode='min', \n                                    save_top_k=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:05:01.943061Z","iopub.execute_input":"2023-01-07T07:05:01.943449Z","iopub.status.idle":"2023-01-07T07:05:01.950175Z","shell.execute_reply.started":"2023-01-07T07:05:01.943410Z","shell.execute_reply":"2023-01-07T07:05:01.949262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n    max_epochs=EPOCH,\n    gpus=1,\n    callbacks=[model_check_point],\n    log_every_n_steps=5\n)\n\nprint(f'Training started...')\ntrain_start = time.time()\n\ntrainer.fit(bert_model, train_data_loader, val_data_loader)\n\ntrain_finish = time.time()\nprint(f'Training finished after {((train_finish - train_start) / 60):.1f} minutes')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:05:01.951524Z","iopub.execute_input":"2023-01-07T07:05:01.952020Z","iopub.status.idle":"2023-01-07T07:05:25.793028Z","shell.execute_reply.started":"2023-01-07T07:05:01.951987Z","shell.execute_reply":"2023-01-07T07:05:25.791838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_step_losses = [i.detach().cpu().item() for i in bert_model.losses_train]\nval_step_losses = [i.detach().cpu().item() for i in bert_model.losses_val]\n\ntrain_steps = [i for i in range(len(train_step_losses))]\nval_steps = [i for i in range(len(val_step_losses))]\n\nloss_stats_train = pd.DataFrame({\n    'step' : train_steps,\n    'train_loss' : train_step_losses,\n})\n\nloss_stats_val = pd.DataFrame({\n    'step' : val_steps,\n    'val_loss' : val_step_losses\n})","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:10:09.319539Z","iopub.execute_input":"2023-01-07T07:10:09.320115Z","iopub.status.idle":"2023-01-07T07:10:09.332096Z","shell.execute_reply.started":"2023-01-07T07:10:09.320073Z","shell.execute_reply":"2023-01-07T07:10:09.330887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bunch = GGBunch()\nplot = ggplot(loss_stats_train) + geom_path(aes('step', 'train_loss'), size=1.3, color='blue') + ggsize(500, 400) + ggtitle('Train Loss')\nbunch.add_plot(plot, 100, 0)\nplot = ggplot(loss_stats_val) + geom_path(aes('step', 'val_loss'), size=1.3, color='red') + ggsize(500, 400) + ggtitle('Validation Loss')\nbunch.add_plot(plot, 700, 0)\nbunch.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:11:34.002284Z","iopub.execute_input":"2023-01-07T07:11:34.002641Z","iopub.status.idle":"2023-01-07T07:11:34.020359Z","shell.execute_reply.started":"2023-01-07T07:11:34.002611Z","shell.execute_reply":"2023-01-07T07:11:34.019214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"markdown","source":"Let's check our model's performance on yet unseen test data ","metadata":{}},{"cell_type":"code","source":"y_hat_test = trainer.predict(bert_model, test_data_loader)\ny_hat_test = np.array(torch.cat(y_hat_test)).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:05:25.796002Z","iopub.execute_input":"2023-01-07T07:05:25.796401Z","iopub.status.idle":"2023-01-07T07:05:29.486011Z","shell.execute_reply.started":"2023-01-07T07:05:25.796362Z","shell.execute_reply":"2023-01-07T07:05:29.484954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = y_test.to_numpy().astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:05:29.487947Z","iopub.execute_input":"2023-01-07T07:05:29.488330Z","iopub.status.idle":"2023-01-07T07:05:29.534437Z","shell.execute_reply.started":"2023-01-07T07:05:29.488288Z","shell.execute_reply":"2023-01-07T07:05:29.531948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_accuracy = accuracy_score(y_test, y_hat_test)\ntest_f1 = f1_score(y_test, y_hat_test, average='macro')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:05:29.537098Z","iopub.status.idle":"2023-01-07T07:05:29.543050Z","shell.execute_reply.started":"2023-01-07T07:05:29.542792Z","shell.execute_reply":"2023-01-07T07:05:29.542818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy : {test_accuracy}')\nprint(f'F1 Score : {test_f1}')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T07:05:29.545940Z","iopub.status.idle":"2023-01-07T07:05:29.548557Z","shell.execute_reply.started":"2023-01-07T07:05:29.548276Z","shell.execute_reply":"2023-01-07T07:05:29.548303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, we got decent results, beating baseline model's performance","metadata":{}}]}